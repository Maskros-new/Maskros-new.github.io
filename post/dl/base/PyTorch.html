<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Noto Sans SC:300,300italic,400,400italic,700,700italic|Noto Serif SC:300,300italic,400,400italic,700,700italic|Fira Code:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"maskros.top","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":false,"style":"default"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="ref: PyTorch文档  PyTorch 是是基于以下两个目的而打造的python科学计算框架：  无缝替换NumPy，利用GPU的算力来加速神经网络 通过自动微分机制，来让神经网络的实现变得更加容易">
<meta property="og:type" content="article">
<meta property="og:title" content="PyTorch基础">
<meta property="og:url" content="https://maskros.top/post/dl/base/PyTorch.html">
<meta property="og:site_name" content="Maskros&#39; Blog">
<meta property="og:description" content="ref: PyTorch文档  PyTorch 是是基于以下两个目的而打造的python科学计算框架：  无缝替换NumPy，利用GPU的算力来加速神经网络 通过自动微分机制，来让神经网络的实现变得更加容易">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-09-10T15:00:00.000Z">
<meta property="article:modified_time" content="2022-09-25T05:23:18.904Z">
<meta property="article:author" content="Maskros">
<meta property="article:tag" content="note">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="python">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://maskros.top/post/dl/base/PyTorch.html">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>PyTorch基础 | Maskros' Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="Maskros' Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Maskros' Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://maskros.top/post/dl/base/PyTorch.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/logo_Maskros.jpg">
      <meta itemprop="name" content="Maskros">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Maskros' Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          PyTorch基础
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-09-10 23:00:00" itemprop="dateCreated datePublished" datetime="2022-09-10T23:00:00+08:00">2022-09-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-09-25 13:23:18" itemprop="dateModified" datetime="2022-09-25T13:23:18+08:00">2022-09-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NOTE/" itemprop="url" rel="index"><span itemprop="name">NOTE</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/post/dl/base/PyTorch.html#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/post/dl/base/PyTorch.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><blockquote>
<p>ref: <a href="pytorch.apachecn.org">PyTorch文档</a></p>
</blockquote>
<p>PyTorch 是是基于以下两个目的而打造的python科学计算框架：</p>
<ul>
<li>无缝替换NumPy，利用GPU的算力来加速神经网络</li>
<li>通过自动微分机制，来让神经网络的实现变得更加容易</li>
</ul>
<span id="more"></span>
<h2 id="基础知识">基础知识</h2>
<h3 id="张量">张量</h3>
<p>tensor</p>
<h4 id="初始化">初始化</h4>
<ol>
<li>
<p><strong>直接生成张量</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
</li>
<li>
<p><strong>通过numpy数组生成</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">np_array <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
x_np <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np_array<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
</li>
<li>
<p><strong>通过已有的张量来生成新的张量</strong></p>
<p>继承已有张量的数据属性（结构、类型），也可以重写新类型</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x_ones <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>   <span class="token comment"># 保留 x_data 的属性</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Ones Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>x_ones<span class="token punctuation">}</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>

x_rand <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand_like<span class="token punctuation">(</span>x_data<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>   <span class="token comment"># 重写 x_data 的数据类型</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Random Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>x_rand<span class="token punctuation">}</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li>
<p><strong>通过指定数据维度来生成张量</strong></p>
<p><code>shape</code>是元组类型, 用来描述张量的维数, 下面3个函数通过传入<code>shape</code>来指定生成张量的维数。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token punctuation">)</span>
rand_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>
ones_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>
zeros_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Random Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>rand_tensor<span class="token punctuation">}</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Ones Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>ones_tensor<span class="token punctuation">}</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Zeros Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>zeros_tensor<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
</ol>
<h4 id="属性">属性</h4>
<p>维数<code>shape</code>、数据类型<code>dtype</code>以及它们所存储的设备(CPU或GPU)<code>device</code></p>
<h4 id="运算">运算</h4>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 判断当前环境GPU是否可用, 然后将tensor导入GPU内运行</span>
<span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p><strong>索引和切片</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>            <span class="token comment"># 将第1列(从0开始)的数据全部赋值为0</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p><strong>拼接</strong></p>
<p><code>torch.cat</code> 或 <code>torch.stack</code>，dim为拼接方向的维度</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">t1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>tensor<span class="token punctuation">,</span> tensor<span class="token punctuation">,</span> tensor<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>t1<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p><strong>张量乘积和矩阵乘法</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 逐个相乘，二者等价</span>
tensor<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>
tensor <span class="token operator">*</span> tensor

<span class="token comment"># 矩阵乘法</span>
tensor<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
tensor @ tensor<span class="token punctuation">.</span>T<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>自动赋值运算</strong></p>
<p>自动赋值运算通常在方法后有 <code>_</code> 作为后缀，例如: <code>x.copy_(y)</code>, <code>x.t_()</code>操作会改变 <code>x</code> 的取值。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor<span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<blockquote>
<p>自动赋值运算虽然可以节省内存, 但在求导时会因为丢失了中间过程而导致一些问题, 所以我们并不鼓励使用它。</p>
</blockquote>
<h3 id="autograd">Autograd</h3>
<p><code>torch.autograd</code>是 PyTorch 的自动差分引擎，可为神经网络训练提供支持。</p>
<p>ex：一个训练步骤示例</p>
<p>从<code>torchvision</code>加载了经过预训练的 resnet18 模型。 我们创建一个随机数据张量来表示具有 3 个通道的单个图像，高度&amp;宽度为 64，其对应的<code>label</code>初始化为一些随机值。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">,</span> torchvision
model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
data <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>
labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>正向传播。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">prediction <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token comment"># forward pass</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>反向传播，Autograd 会为每个模型参数计算梯度并将其存储在参数的<code>.grad</code>属性中。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">loss <span class="token operator">=</span> <span class="token punctuation">(</span>prediction <span class="token operator">-</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># backward pass</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>接下来，我们加载一个优化器，在本例中为 SGD，学习率为 0.01，动量为 0.9。 我们在优化器中注册模型的所有参数。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">optim <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>调用<code>.step()</code>启动梯度下降。 优化器通过<code>.grad</code>中存储的梯度来调整每个参数。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#gradient descent</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h4 id="autograd的微分">Autograd的微分</h4>
<p>ex：<code>autograd</code>如何收集梯度。首先用<code>requires_grad=True</code>创建两个张量<code>a</code>和<code>b</code>。 这向<code>autograd</code>发出信号，应跟踪对它们的所有操作。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>从<code>a</code>和<code>b</code>创建另一个张量<code>Q</code>。假设<code>a</code>和<code>b</code>是参数，<code>Q</code>是误差，在<code>Q</code>上调用<code>.backward()</code>时，Autograd 将计算这些梯度并将其存储在各个张量的<code>.grad</code>属性中。</p>
<p>我们需要在<code>Q.backward()</code>中显式传递<code>gradient</code>参数，因为它是向量。 <code>gradient</code>是与<code>Q</code>形状相同的张量，它表示<code>Q</code>相对于本身的梯度，即 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="2.149ex" role="img" focusable="false" viewbox="0 -750 600 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mn"><text data-variant="double-struck" transform="scale(1,-1)" font-size="884px">𝟙</text></g></g></g></g></svg></mjx-container> ；同样，我们也可以将<code>Q</code>聚合为一个标量，然后隐式地向后调用，例如<code>Q.sum().backward()</code>。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">Q <span class="token operator">=</span> <span class="token number">3</span><span class="token operator">*</span>a<span class="token operator">**</span><span class="token number">3</span> <span class="token operator">-</span> b<span class="token operator">**</span><span class="token number">2</span>
external_grad <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Q<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>gradient<span class="token operator">=</span>external_grad<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>检查沉积的梯度，无误。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 结果都是true</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token number">9</span><span class="token operator">*</span>a<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">==</span> a<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token operator">*</span>b <span class="token operator">==</span> b<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h4 id="计算图">计算图</h4>
<p>Autograd 在由函数对象组成的有向无环图（DAG）中记录数据（张量）和所有已执行的操作（以及由此产生的新张量）。 在此 DAG 中，叶子是输入张量，根是输出张量。 通过从根到叶跟踪此图，可以使用链式规则自动计算梯度。</p>
<p>在正向传播中，Autograd 同时执行两项操作：</p>
<ul>
<li>运行请求的操作以计算结果张量</li>
<li>在 DAG 中维护操作的梯度函数</li>
</ul>
<p>当在 DAG 根目录上调用<code>.backward()</code>时，反向传递开始。 Autograd执行：</p>
<ul>
<li>从每个<code>.grad_fn</code>计算梯度，将它们累积在各自的张量的<code>.grad</code>属性中</li>
<li>使用链式规则一直传播到叶子张量</li>
</ul>
<p><strong>DAG 在 PyTorch 中是动态的</strong>。要注意的重要一点是，图是从头开始重新创建的； 在每个<code>.backward()</code>调用之后，Autograd 开始填充新图。 可以根据需要在每次迭代中更改形状，大小和操作。</p>
<h4 id="从dag中排除">从DAG中排除</h4>
<p>对于不需要梯度的张量，将<code>requires_grad</code>属性设置为<code>False</code>会将其从梯度计算 DAG 中排除。但注意，即使只有一个输入张量该属性为<code>True</code>，操作的输出张量也将需要梯度。</p>
<p>在 NN 中，不计算梯度的参数通常称为<strong>冻结参数</strong>。 如果事先知道您不需要这些参数的梯度，则“冻结”模型的一部分会带来性能优势。常见用例：<strong>调整预训练网络(finetuning)</strong></p>
<p>在微调中，我们冻结了大部分模型，通常仅修改分类器层以对新标签进行预测。 ex：加载一个预训练的 resnet18 模型，并冻结所有参数。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token punctuation">,</span> optim

model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># Freeze all the parameters in the network</span>
<span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    param<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>假设我们要在具有 10 个标签的新数据集中微调模型。 在 resnet 中，分类器是最后一个线性层<code>model.fc</code>。 我们可以简单地将其替换为充当我们的分类器的新线性层（默认情况下未冻结）。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">model<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>现在，除了<code>model.fc</code>的参数外，模型中的所有参数都将冻结。 计算梯度的唯一参数是<code>model.fc</code>的权重和偏差。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Optimize only the classifier</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>尽管我们在优化器中注册了所有参数，但唯一可计算梯度的参数（因此会在梯度下降中进行更新）是分类器的权重和偏差<code>torch.no_grad()</code>中的上下文管理器可以使用相同的排除功能。</p>
<h3 id="神经网络">神经网络</h3>
<p>可以使用<code>torch.nn</code>包构建神经网络。<code>nn</code>依赖于<code>autograd</code>来定义模型并对其进行微分。 <code>nn.Module</code>包含层，以及返回<code>output</code>的方法<code>forward(input)</code>。</p>
<p>神经网络的典型训练过程：</p>
<ul>
<li>定义具有一些可学习参数（或权重）的神经网络</li>
<li>遍历输入数据集</li>
<li>通过网络处理输入</li>
<li>计算损失（输出正确的距离有多远）</li>
<li>将梯度传播回网络参数</li>
<li>通常使用简单的更新规则来更新网络的权重：<code>weight = weight - learning_rate * gradient</code></li>
</ul>
<h4 id="定义网络">定义网络</h4>
<p>ex：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F


<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 1 input image channel, 6 output channels, 5x5 square convolution</span>
        <span class="token comment"># kernel</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
        <span class="token comment"># an affine operation: y = Wx + b</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>  <span class="token comment"># 5*5 from image dimension</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># Max pooling over a (2, 2) window</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># If the size is a square, you can specify with a single number</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># flatten all dimensions except the batch dimension</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x


net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">Net<span class="token punctuation">(</span>
  <span class="token punctuation">(</span>conv1<span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">(</span>conv2<span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">(</span>fc1<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">400</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">120</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
  <span class="token punctuation">(</span>fc2<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">120</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">84</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
  <span class="token punctuation">(</span>fc3<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">84</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>只需定义<code>forward</code>函数，就可以使用<code>autograd</code>自动定义<code>backward</code>函数（计算梯度）。 可以在<code>forward</code>函数中使用任何张量操作。</p>
<p>模型的可学习参数由<code>net.parameters()</code>返回。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">params <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>params<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>params<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># conv1's .weight</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>输出：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token number">10</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>尝试一个 <code>32*32</code> 随机输入。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
out <span class="token operator">=</span> net<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>out<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>输出：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.0818</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0857</span><span class="token punctuation">,</span>  <span class="token number">0.0695</span><span class="token punctuation">,</span>  <span class="token number">0.1430</span><span class="token punctuation">,</span>  <span class="token number">0.0191</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1402</span><span class="token punctuation">,</span>  <span class="token number">0.0499</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0737</span><span class="token punctuation">,</span>
         <span class="token operator">-</span><span class="token number">0.0857</span><span class="token punctuation">,</span>  <span class="token number">0.1395</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddmmBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>使用随机梯度将所有参数和反向传播的梯度缓冲区归零：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">net<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
out<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<blockquote>
<p>注意：<code>torch.nn</code>仅支持mini-batch。 整个<code>torch.nn</code>包仅支持作为微型样本而不是单个样本的输入：ex：<code>nn.Conv2d</code>将采用<code>nSamples x nChannels x Height x Width</code>的 4D 张量。如果您只有一个样本，只需使用<code>input.unsqueeze(0)</code>添加一个假批量尺寸。</p>
</blockquote>
<p>总结：</p>
<ul>
<li><code>torch.Tensor</code>-一个<em>多维数组</em>，支持诸如<code>backward()</code>的自动微分操作。 同样，保持相对于张量的梯度。</li>
<li><code>nn.Module</code>-神经网络模块。 <em>封装参数</em>的便捷方法，并带有将其移动到 GPU，导出，加载等的帮助器。</li>
<li><code>nn.Parameter</code>-一种张量，即将其分配为<code>Module</code>的属性时，自动注册为参数。</li>
<li><code>autograd.Function</code>-实现自动微分操作的正向和反向定义。 每个<code>Tensor</code>操作都会创建至少一个<code>Function</code>节点，该节点连接到创建<code>Tensor</code>的函数，并且编码其历史记录。</li>
</ul>
<h4 id="损失函数">损失函数</h4>
<p>损失函数采用一对（输出，目标）输入，并计算一个值，该值估计输出与目标之间的距离。</p>
<p><code>nn</code>包下有几种不同的<a target="_blank" rel="noopener" href="https://pytorch.org/docs/nn.html#loss-functions">损失函数</a>，一个简单的损失是：<code>nn.MSELoss</code>，它计算输入和目标之间的均方误差，ex：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">output <span class="token operator">=</span> net<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
target <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>  <span class="token comment"># a dummy target, for example</span>
target <span class="token operator">=</span> target<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># make it the same shape as output</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor<span class="token punctuation">(</span><span class="token number">1.1649</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>MseLossBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>现在，如果使用<code>.grad_fn</code>属性向后跟随<code>loss</code>，您将看到一个计算图，如下所示：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token builtin">input</span> <span class="token operator">-</span><span class="token operator">&gt;</span> conv2d <span class="token operator">-</span><span class="token operator">&gt;</span> relu <span class="token operator">-</span><span class="token operator">&gt;</span> maxpool2d <span class="token operator">-</span><span class="token operator">&gt;</span> conv2d <span class="token operator">-</span><span class="token operator">&gt;</span> relu <span class="token operator">-</span><span class="token operator">&gt;</span> maxpool2d
      <span class="token operator">-</span><span class="token operator">&gt;</span> view <span class="token operator">-</span><span class="token operator">&gt;</span> linear <span class="token operator">-</span><span class="token operator">&gt;</span> relu <span class="token operator">-</span><span class="token operator">&gt;</span> linear <span class="token operator">-</span><span class="token operator">&gt;</span> relu <span class="token operator">-</span><span class="token operator">&gt;</span> linear
      <span class="token operator">-</span><span class="token operator">&gt;</span> MSELoss
      <span class="token operator">-</span><span class="token operator">&gt;</span> loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>当我们调用<code>loss.backward()</code>时，整个图将被微分。 并且图中具有<code>requires_grad=True</code>的所有张量将随梯度累积其<code>.grad</code>张量。</p>
<p>为了说明，让我们向后走几步：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>grad_fn<span class="token punctuation">)</span>  <span class="token comment"># MSELoss</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>grad_fn<span class="token punctuation">.</span>next_functions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># Linear</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>grad_fn<span class="token punctuation">.</span>next_functions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>next_functions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># ReLU</span>

<span class="token comment"># 输出</span>
<span class="token operator">&lt;</span>MseLossBackward0 <span class="token builtin">object</span> at <span class="token number">0x7f71283dd048</span><span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>AddmmBackward0 <span class="token builtin">object</span> at <span class="token number">0x7f71283dd7f0</span><span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>AccumulateGrad <span class="token builtin">object</span> at <span class="token number">0x7f71283dd7f0</span><span class="token operator">&gt;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="反向传播">反向传播</h4>
<p>要反向传播误差，我们要做的只是<code>loss.backward()</code>。 不过，需要清除现有的梯度，否则梯度将累积到现有的梯度中。</p>
<p>ex：看一下<code>backward</code>前后<code>conv1</code>的偏差梯度</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">net<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># zeroes the gradient buffers of all parameters</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'conv1.bias.grad before backward'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>conv1<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>

loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'conv1.bias.grad after backward'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>conv1<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">conv1<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>grad before backward
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
conv1<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>grad after backward
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.0188</span><span class="token punctuation">,</span>  <span class="token number">0.0172</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0044</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0141</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0058</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0013</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="更新权重">更新权重</h4>
<p>实践中使用的最简单的更新规则是随机梯度下降（SGD）：</p>
<p><code>weight = weight - learning_rate * gradient</code></p>
<p>使用神经网络时，您希望使用各种不同的更新规则，例如 SGD，Nesterov-SGD，Adam，RMSProp 等。为实现此目的，<code>torch.optim</code>可实现所有这些方法。 使用它非常简单：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim

<span class="token comment"># create your optimizer</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>

<span class="token comment"># in your training loop:</span>
optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment"># zero the gradient buffers</span>
output <span class="token operator">=</span> net<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># Does the update</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<blockquote>
<p>注意：使用<code>optimizer.zero_grad()</code>将梯度缓冲区手动设置为零。 这是因为如反向传播部分中所述累积了梯度。</p>
</blockquote>
<h3 id="训练分类器">训练分类器</h3>
<h4 id="数据">数据</h4>
<p>处理图像，文本，音频或视频数据时，可以使用将数据加载到 NumPy 数组中的标准 Python 包。 然后，您可以将该数组转换为<code>torch.*Tensor</code>。</p>
<ul>
<li>对于图像，Pillow，OpenCV 等包很有用</li>
<li>对于音频，请使用 SciPy 和 librosa 等包</li>
<li>对于文本，基于 Python 或 Cython 的原始加载，或者 NLTK 和 SpaCy 很有用</li>
</ul>
<p>专门针对视觉的<code>torchvision</code>包，其中包含用于常见数据集（例如 Imagenet，CIFAR10，MNIST 等）的数据加载器，以及用于图像（即<code>torchvision.datasets</code>和<code>torch.utils.data.DataLoader</code>）的数据转换器。</p>
<pre><code>#### 训练
</code></pre>
<p>ex：将使用 CIFAR10 数据集。 它具有以下类别：“飞机”，“汽车”，“鸟”，“猫”，“鹿”，“狗”，“青蛙”，“马”，“船”，“卡车”。 CIFAR-10 中的图像尺寸为<code>3x32x32</code>，即尺寸为<code>32x32</code>像素的 3 通道彩色图像。</p>
<p>应按顺序执行以下步骤：</p>
<ol>
<li>使用<code>torchvision</code>加载并标准化 CIFAR10 训练和测试数据集</li>
<li>定义卷积神经网络</li>
<li>定义损失函数</li>
<li>根据训练数据训练网络</li>
<li>在测试数据上测试网络</li>
</ol>
<p>1.<strong>加载并标准化 CIFAR10</strong></p>
<p>TorchVision 数据集的输出是<code>[0, 1]</code>范围的<code>PILImage</code>图像。 我们将它们转换为归一化范围<code>[-1, 1]</code>的张量</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torchvision
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms

transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

trainset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                        download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
trainloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>trainset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>
                                          shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

testset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                                       download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
testloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>testset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>
                                         shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

classes <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'plane'</span><span class="token punctuation">,</span> <span class="token string">'car'</span><span class="token punctuation">,</span> <span class="token string">'bird'</span><span class="token punctuation">,</span> <span class="token string">'cat'</span><span class="token punctuation">,</span>
           <span class="token string">'deer'</span><span class="token punctuation">,</span> <span class="token string">'dog'</span><span class="token punctuation">,</span> <span class="token string">'frog'</span><span class="token punctuation">,</span> <span class="token string">'horse'</span><span class="token punctuation">,</span> <span class="token string">'ship'</span><span class="token punctuation">,</span> <span class="token string">'truck'</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>展示一些训练图像</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token comment"># functions to show an image</span>

<span class="token keyword">def</span> <span class="token function">imshow</span><span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">:</span>
    img <span class="token operator">=</span> img <span class="token operator">/</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token number">0.5</span>     <span class="token comment"># unnormalize</span>
    npimg <span class="token operator">=</span> img<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>npimg<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># get some random training images</span>
dataiter <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>trainloader<span class="token punctuation">)</span>
images<span class="token punctuation">,</span> labels <span class="token operator">=</span> dataiter<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># show images</span>
imshow<span class="token punctuation">(</span>torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># print labels</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'%5s'</span> <span class="token operator">%</span> classes<span class="token punctuation">[</span>labels<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>2.<strong>定义卷积神经网络</strong></p>
<p>之前从“神经网络”部分复制神经网络，然后对其进行修改以获取 3 通道图像（而不是定义的 1 通道图像）。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>3.<strong>定义损失函数和优化器</strong></p>
<p>使用分类交叉熵损失和带动量的 SGD</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim

criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>4.<strong>训练网络</strong></p>
<p>只需遍历数据迭代器，然后将输入馈送到网络并进行优化即可。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># loop over the dataset multiple times</span>

    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>trainloader<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># get the inputs; data is a list of [inputs, labels]</span>
        inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data

        <span class="token comment"># zero the parameter gradients</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># forward + backward + optimize</span>
        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># print statistics</span>
        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">2000</span> <span class="token operator">==</span> <span class="token number">1999</span><span class="token punctuation">:</span>    <span class="token comment"># print every 2000 mini-batches</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%d, %5d] loss: %.3f'</span> <span class="token operator">%</span>
                  <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> running_loss <span class="token operator">/</span> <span class="token number">2000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            running_loss <span class="token operator">=</span> <span class="token number">0.0</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished Training'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>快速保存我们训练过的模型：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">PATH <span class="token operator">=</span> <span class="token string">'./cifar_net.pth'</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>5.<strong>根据测试数据测试网络</strong></p>
<p>我们已经在训练数据集中对网络进行了 2 次训练，下面将通过预测神经网络输出的类别标签并根据实际情况进行检查来进行检查。 如果预测正确，则将样本添加到正确预测列表中。</p>
<p>显示测试集中的几张图像</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">dataiter <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>testloader<span class="token punctuation">)</span>
images<span class="token punctuation">,</span> labels <span class="token operator">=</span> dataiter<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># print images</span>
imshow<span class="token punctuation">(</span>torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'GroundTruth: '</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'%5s'</span> <span class="token operator">%</span> classes<span class="token punctuation">[</span>labels<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>重新加载保存的模型（这里不需要保存和重新加载模型，只是为了说明如何这样做）：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>神经网络对以上示例的看法：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>输出10类的能量， 一个类别的能量越高，网络就认为该图像属于特定类别。 因此让我们获取最高能量的指数，打印示例的测试结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">_<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Predicted: '</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'%5s'</span> <span class="token operator">%</span> classes<span class="token punctuation">[</span>predicted<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span>
                              <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>网络在整个数据集上的表现：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">correct <span class="token operator">=</span> <span class="token number">0</span>
total <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> testloader<span class="token punctuation">:</span>
        images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data
        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
        _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Accuracy of the network on the 10000 test images: %d %%'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>
    <span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>哪些类的表现良好，哪些类的表现不佳：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">class_correct <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">.</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
class_total <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">.</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> testloader<span class="token punctuation">:</span>
        images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data
        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
        _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        c <span class="token operator">=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            label <span class="token operator">=</span> labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            class_correct<span class="token punctuation">[</span>label<span class="token punctuation">]</span> <span class="token operator">+=</span> c<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            class_total<span class="token punctuation">[</span>label<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Accuracy of %5s : %2d %%'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>
        classes<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">100</span> <span class="token operator">*</span> class_correct<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">/</span> class_total<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="gpu">GPU</h4>
<p>将神经网络转移到GPU上</p>
<p>首先将我们的设备定义为第一个可见的 cuda 设备：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>

<span class="token comment"># Assuming that we are on a CUDA machine, this should print a CUDA device:</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这些方法将递归遍历所有模块，并将其参数和缓冲区转换为 CUDA 张量：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>还必须将每一步的输入和目标也发送到 GPU：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="sb">sb</h3>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/note/" rel="tag"># note</a>
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
              <a href="/tags/python/" rel="tag"># python</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/post/dl/base/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%E5%9F%BA%E6%9C%AC%E7%90%86%E8%AE%BA.html" rel="prev" title="深度学习：基本理论">
      <i class="fa fa-chevron-left"></i> 深度学习：基本理论
    </a></div>
      <div class="post-nav-item">
    <a href="/post/dl/cnn/AlexNet.html" rel="next" title="CNN经典网络：AlexNet">
      CNN经典网络：AlexNet <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="nav-text">基础知识</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%A0%E9%87%8F"><span class="nav-text">张量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#autograd"><span class="nav-text">Autograd</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-text">神经网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E5%88%86%E7%B1%BB%E5%99%A8"><span class="nav-text">训练分类器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sb"><span class="nav-text">sb</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Maskros"
      src="/img/logo_Maskros.jpg">
  <p class="site-author-name" itemprop="name">Maskros</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">62</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">53</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Maskros-new" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Maskros-new" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:haohangjian2002@gmail.com" title="E-Mail → mailto:haohangjian2002@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://space.bilibili.com/355516889" title="Bilibili → https:&#x2F;&#x2F;space.bilibili.com&#x2F;355516889" rel="noopener" target="_blank"><i class="fas fa-tv fa-fw"></i>Bilibili</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://codeforces.com/profile/1ronMaker" title="Codeforces1 → https:&#x2F;&#x2F;codeforces.com&#x2F;profile&#x2F;1ronMaker" rel="noopener" target="_blank"><i class="far fa-chart-bar fa-fw"></i>Codeforces1</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://codeforces.com/profile/7hhnewbee" title="Codeforces2 → https:&#x2F;&#x2F;codeforces.com&#x2F;profile&#x2F;7hhnewbee" rel="noopener" target="_blank"><i class="far fa-chart-bar fa-fw"></i>Codeforces2</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.cnblogs.com/lipoicyclic/" title="https:&#x2F;&#x2F;www.cnblogs.com&#x2F;lipoicyclic&#x2F;" rel="noopener" target="_blank">脂环</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://coinc1dens.me/" title="https:&#x2F;&#x2F;coinc1dens.me&#x2F;" rel="noopener" target="_blank">x1</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://rayjinx.com/" title="https:&#x2F;&#x2F;rayjinx.com&#x2F;" rel="noopener" target="_blank">栗悟饭</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://nerdzzh.me/" title="https:&#x2F;&#x2F;nerdzzh.me&#x2F;" rel="noopener" target="_blank">edicius</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://zwh-sdu.github.io/" title="https:&#x2F;&#x2F;zwh-sdu.github.io&#x2F;" rel="noopener" target="_blank">zwh</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Maskros</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'Nmc1pCkN608WUnjzl1OVUJwp-gzGzoHsz',
      appKey     : 'AgMMODlKtVQJ8D2ksYM7tqFv',
      placeholder: "Leave your thoughts behind~",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
